{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7eff9c0495d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = map(lambda x: to_ix[x.lower()] if x in to_ix else to_ix['<unk>'], seq)\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "    \n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, tag_count, tag_embedding_size):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embeds = nn.Embedding(tag_count, tag_embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_dim + tag_embedding_size, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        \n",
    "        # number of filters for 2, 3, 4 sized convs\n",
    "        self.c1 = 4\n",
    "        self.c2 = 2\n",
    "        self.c3 = 2\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, self.c1, (2, hidden_dim), padding=(1,0))\n",
    "        self.conv2 = nn.Conv2d(1, self.c2, (3, hidden_dim), padding=(1,0))\n",
    "        self.conv3 = nn.Conv2d(1, self.c3, (4, hidden_dim), padding=(2,0))\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim + self.c1 + self.c2 + self.c3, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "        self.transitions.data[1][2] = -100000\n",
    "        self.transitions.data[2][0] = -100000\n",
    "        self.transitions.data[1][1] = -100000\n",
    "        self.transitions.data[2][tag_to_ix[START_TAG]] = -100000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    \n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence, sentence_pos):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        pos_embeds_out = self.pos_embeds(sentence_pos).view(len(sentence), 1, -1)\n",
    "        tot_embedding = torch.cat((embeds, pos_embeds_out), dim=2)\n",
    "        lstm_out, self.hidden = self.lstm(tot_embedding, self.hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.view(1, 1, len(sentence), self.hidden_dim)\n",
    "\n",
    "        conv1_out = self.conv1(lstm_out)\n",
    "        conv1_out = conv1_out.permute(0, 3, 2, 1)\n",
    "        conv1_out = conv1_out.view(-1, self.c1)\n",
    "        conv1_out = conv1_out[:len(sentence), :]\n",
    "        \n",
    "        conv2_out = self.conv2(lstm_out)\n",
    "        conv2_out = conv2_out.permute(0, 3, 2, 1)\n",
    "        conv2_out = conv2_out.view(-1, self.c2)\n",
    "        conv2_out = conv2_out[:len(sentence), :]\n",
    "        \n",
    "        conv3_out = self.conv3(lstm_out)\n",
    "        conv3_out = conv3_out.permute(0, 3, 2, 1)\n",
    "        conv3_out = conv3_out.view(-1, self.c3)\n",
    "        conv3_out = conv3_out[:len(sentence), :]\n",
    "        \n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        \n",
    "        out = torch.cat((lstm_out, conv1_out, conv2_out, conv3_out), dim=1)\n",
    "        out = self.hidden2tag(out)\n",
    "        return out\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, sentence_pos, tags):\n",
    "        feats = self._get_lstm_features(sentence, sentence_pos)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence, sentence_pos):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence, sentence_pos)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle, math\n",
    "import numpy as np\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 25\n",
    "POS_EMBEDDING_DIM = 25\n",
    "HIDDEN_DIM = 20\n",
    "\n",
    "train_file_x = 'data/restaurants_train_x.txt'\n",
    "train_file_y = 'data/restaurants_train_y.txt'\n",
    "\n",
    "test_file_x = 'data/restaurants_test_x.txt'\n",
    "test_file_y = 'data/restaurants_test_y.txt'\n",
    "\n",
    "def make_list(path):\n",
    "    f = open(path)\n",
    "    return [x.split() for x in f]\n",
    "\n",
    "train_x = make_list(train_file_x)\n",
    "train_y = make_list(train_file_y)\n",
    "test_x = make_list(test_file_x)\n",
    "test_y = make_list(test_file_y)\n",
    "\n",
    "with open('vec_dic.pickle', 'rb') as f:\n",
    "    vec_dic = pickle.load(f)\n",
    "\n",
    "word2id = {}\n",
    "id2word = {}\n",
    "embedding_matrix = []\n",
    "\n",
    "for word in vec_dic:\n",
    "    word2id[word] = len(word2id)\n",
    "    id2word[len(word2id)-1] = word\n",
    "    embedding_matrix.append(vec_dic[word])\n",
    "            \n",
    "word2id['<unk>'] = len(word2id)\n",
    "id2word[len(word2id)-1] = '<unk>'\n",
    "\n",
    "# add the embedding corresponding to random word to the embedding_matrix\n",
    "embedding_matrix.append(np.random.randn(EMBEDDING_DIM).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "# now lets encode the pos tags\n",
    "pos2id = {}\n",
    "\n",
    "def update_pos2id(word):\n",
    "    if word in pos2id:\n",
    "        return pos2id[word]\n",
    "    pos2id[word] = len(pos2id)\n",
    "    return pos2id[word]\n",
    "\n",
    "train_pos = []\n",
    "\n",
    "for sentence in train_x:\n",
    "    train_pos.append(map(update_pos2id, [x[1] for x in pos_tag(sentence)]))\n",
    "pos2id['<unk>'] = len(pos2id)\n",
    "\n",
    "# save pos2id to use in production code\n",
    "with open('pos2id.pickle', 'wb') as f:\n",
    "    pickle.dump(pos2id, f)\n",
    "    \n",
    "test_pos = []\n",
    "for sentence in test_x:\n",
    "    test_pos.append(map(lambda tag: pos2id[tag] if tag in pos2id else pos2id['<unk>'], [x[1] for x in pos_tag(sentence)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193515"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the glove vectors and save to a pickle_file\n",
    "len(id2word)\n",
    "# word2id['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193515"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)\n",
    "# len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch done!\n",
      "(0.5534709193245778, 0.5694980694980695)\n",
      "Saving the best model up to now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_score 0.561370\n",
      "epoch done!\n",
      "(0.5936883629191322, 0.581081081081081)\n",
      "Saving the best model up to now\n",
      "f_score 0.587317\n",
      "epoch done!\n",
      "(0.620253164556962, 0.6621621621621622)\n",
      "Saving the best model up to now\n",
      "f_score 0.640523\n",
      "epoch done!\n",
      "(0.6340508806262231, 0.6254826254826255)\n",
      "f_score 0.629738\n",
      "epoch done!\n",
      "(0.6687763713080169, 0.611969111969112)\n",
      "f_score 0.639113\n",
      "epoch done!\n",
      "(0.6409774436090225, 0.6583011583011583)\n",
      "Saving the best model up to now\n",
      "f_score 0.649524\n",
      "epoch done!\n",
      "(0.6812227074235808, 0.6023166023166023)\n",
      "f_score 0.639344\n",
      "epoch done!\n",
      "(0.660377358490566, 0.6081081081081081)\n",
      "f_score 0.633166\n"
     ]
    }
   ],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "HIDDEN_DIM = 20\n",
    "\n",
    "# 100, 40 -- 1st epoch 35\n",
    "tag2id = {\"0\": 0, \"1\": 1, \"2\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "\n",
    "model = BiLSTM_CRF(len(word2id), tag2id, EMBEDDING_DIM, HIDDEN_DIM, len(pos2id), POS_EMBEDDING_DIM)\n",
    "model.word_embeds.weight = nn.Parameter(torch.Tensor(embedding_matrix))\n",
    "# model = torch.load(\"best_model_lstm_crf_pos.pt\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# Check predictions before training\n",
    "# with torch.no_grad():\n",
    "#     precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "#     precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "#     print(model(precheck_sent))\n",
    "\n",
    "best_f = 0\n",
    "scores = []\n",
    "\n",
    "for epoch in range(\n",
    "        30):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for x, x_pos, y in zip(train_x, train_pos, train_y):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(x, word2id)\n",
    "        sentence_pos = torch.tensor(x_pos, dtype=torch.long)\n",
    "        targets = torch.tensor([tag2id[t] for t in y], dtype=torch.long)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, sentence_pos, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    print('epoch done!')\n",
    "    \n",
    "    if epoch%1==0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        s = 0\n",
    "        g = 0\n",
    "        s_g = 0\n",
    "        \n",
    "        for x, x_pos, y in zip(test_x, test_pos, test_y):\n",
    "            sentence_in = prepare_sequence(x, word2id)\n",
    "            sentence_pos = torch.tensor(x_pos, dtype=torch.long)\n",
    "            _, prediction = model(sentence_in, sentence_pos)\n",
    "\n",
    "            prediction = torch.LongTensor(prediction)\n",
    "            y = torch.LongTensor(map(int, y))\n",
    "            \n",
    "            prediction = prediction.tolist()\n",
    "            y = y.tolist()\n",
    "            \n",
    "            i = 0\n",
    "            while(i < len(prediction)):\n",
    "                if prediction[i]==1:\n",
    "                    s += 1\n",
    "                    if y[i]==1:\n",
    "                        g += 1\n",
    "                        i += 1\n",
    "                        if i>=len(prediction):\n",
    "                            s_g += 1\n",
    "                            continue\n",
    "                        while(i<len(prediction) and prediction[i]==2):\n",
    "                            if not y[i]==2:\n",
    "                                i += 1\n",
    "                                break\n",
    "                            i += 1\n",
    "                        else:\n",
    "                            s_g += 1\n",
    "                    else:\n",
    "                        i += 1\n",
    "                elif y[i]==1:\n",
    "                    g += 1\n",
    "                    i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "        \n",
    "        precision += float(s_g) / s\n",
    "        recall += float(s_g) / g\n",
    "        print(precision, recall)\n",
    "#             if len(y) == (prediction==y).sum().tolist():\n",
    "#                 correct += 1\n",
    "        \n",
    "        f_score = 2 * precision * recall / (precision + recall)\n",
    "        scores.append(f_score)\n",
    "        \n",
    "        if best_f < f_score:\n",
    "            best_f = f_score\n",
    "            # save the model\n",
    "            print(\"Saving the best model up to now\")\n",
    "            torch.save(model, \"best_model_lstm_crf_cnn_pos.pt\")\n",
    "        \n",
    "        print \"f_score %f\" % f_score\n",
    "\n",
    "# Check predictions after training\n",
    "# with torch.no_grad():\n",
    "#     precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "#     print(model(precheck_sent))\n",
    "# We got it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9fa91c0290>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9fb72aad10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
